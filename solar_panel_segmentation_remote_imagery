{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"654c794449bd42378ad0ff1ba20a3842":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77ac0e5761554e789f001c1045129ea8","IPY_MODEL_3db63fd099ba4a2a8d3ffcaa147b6011","IPY_MODEL_5a5479ef19af4814b4a227ea44ffd90a"],"layout":"IPY_MODEL_60f4949511b44ae499946129cee86819"}},"77ac0e5761554e789f001c1045129ea8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69079a20dea64e91885053bf2cc54a4c","placeholder":"​","style":"IPY_MODEL_5ca7b048742c49e986dd8e30727367a7","value":"model.safetensors: 100%"}},"3db63fd099ba4a2a8d3ffcaa147b6011":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f26197afbe3469cb2d27ea32f7257ee","max":31471874,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d026f74db1264804b09f4b93da7bf720","value":31471874}},"5a5479ef19af4814b4a227ea44ffd90a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e52204a5e84f419994c7017fc2b3bbf8","placeholder":"​","style":"IPY_MODEL_0b074c585dd5460f892711429f1d78aa","value":" 31.5M/31.5M [00:00&lt;00:00, 56.8MB/s]"}},"60f4949511b44ae499946129cee86819":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69079a20dea64e91885053bf2cc54a4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ca7b048742c49e986dd8e30727367a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f26197afbe3469cb2d27ea32f7257ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d026f74db1264804b09f4b93da7bf720":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e52204a5e84f419994c7017fc2b3bbf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b074c585dd5460f892711429f1d78aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10783793,"sourceType":"datasetVersion","datasetId":6691299}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install ultralytics albumentations==1.3.0 timm==0.9.2 -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T09:05:38.452631Z","iopub.execute_input":"2025-03-18T09:05:38.452939Z","iopub.status.idle":"2025-03-18T09:05:41.887657Z","shell.execute_reply.started":"2025-03-18T09:05:38.452914Z","shell.execute_reply":"2025-03-18T09:05:41.886436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\nimport os\nimport timm\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport cv2\nfrom sklearn.model_selection import KFold\nimport numpy as np\nfrom tqdm import tqdm\nfrom torch.amp import autocast, GradScaler  # Fixed import\nfrom sklearn.metrics import mean_absolute_error\n\n# Fixed Albumentations version warning\nos.environ['NO_ALBUMENTATIONS_UPDATE'] = '1'\n\n# Enhanced Dataset with Metadata\nclass SolarPanelDataset(Dataset):\n    def __init__(self, dataframe, transform=None, to_train=True):\n        self.dataframe = dataframe\n        self.transform = transform\n        self.to_train = to_train\n        self.placement_map = {\"roof\": 0, \"openspace\": 1, \"r_openspace\": 2, \"S-unknown\": 3}\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        image = cv2.imread(row[\"path\"])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Correct color conversion\n\n        # Improved metadata encoding\n        metadata = torch.zeros(5)\n        metadata[0] = 1.0 if row[\"img_origin\"] == \"D\" else 0.0\n        placement = self.placement_map.get(row[\"placement\"], 3)\n        metadata[1 + placement] = 1.0  # One-hot encoding\n\n        if self.transform:\n            image = self.transform(image=image)['image']\n\n        if self.to_train:\n            target = torch.tensor([row[\"boil_nbr\"], row[\"pan_nbr\"]], dtype=torch.float32)\n            return image, metadata, target\n        return image, metadata\n\n# Enhanced Model with Metadata\nclass EfficientNetV2Meta(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = timm.create_model(\"tf_efficientnetv2_b3\", pretrained=True, num_classes=0)  # Larger backbone\n        self.meta_processor = nn.Sequential(\n            nn.Linear(5, 128),\n            nn.LayerNorm(128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 64)\n        )\n        self.attention = nn.MultiheadAttention(embed_dim=64, num_heads=4)\n        self.regressor = nn.Sequential(\n            nn.Linear(self.backbone.num_features + 64, 512),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, 2),\n            nn.Softplus()  # Better for count predictions\n        )\n\n    def forward(self, image, metadata):\n        img_features = self.backbone(image)\n        meta_features = self.meta_processor(metadata.unsqueeze(0))\n        attn_output, _ = self.attention(meta_features, meta_features, meta_features)\n        combined = torch.cat([img_features, attn_output.squeeze(0)], dim=1)\n        return self.regressor(combined)\n\n# Advanced Augmentation\ntrain_transform = A.Compose([\n    A.RandomResizedCrop(512, 512, scale=(0.7, 1.0)),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n    A.CLAHE(clip_limit=4.0, p=0.5),\n    A.HueSaturationValue(p=0.3),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\ntest_transform = A.Compose([\n    A.Resize(512, 512),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\n# Training Configuration\ndef train(fold=0, epochs=10, batch_size=16):\n    train_df = pd.read_csv(\"/kaggle/input/lacuna-solar-survey-challenge/Train.csv\")\n    train_df = train_df.groupby(\"ID\").agg({\n        \"boil_nbr\": \"sum\",\n        \"pan_nbr\": \"sum\",\n        \"img_origin\": \"first\",\n        \"placement\": \"first\"\n    }).reset_index()\n    train_df[\"path\"] = \"/kaggle/input/lacuna-solar-survey-challenge/images/\" + train_df[\"ID\"] + \".jpg\"\n\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    splits = list(kf.split(train_df))\n    train_idx, val_idx = splits[fold]\n\n    train_ds = SolarPanelDataset(train_df.iloc[train_idx], transform=train_transform)\n    val_ds = SolarPanelDataset(train_df.iloc[val_idx], transform=test_transform)\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size, \n                             shuffle=True, num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_ds, batch_size=batch_size*2, \n                           shuffle=False, num_workers=4, pin_memory=True)\n\n    model = EfficientNetV2Meta().cuda()\n    criterion = nn.HuberLoss(delta=1.0)  # Improved loss function\n    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n    scaler = GradScaler()\n\n    best_mae = float('inf')\n    for epoch in range(epochs):\n        # Training loop\n        model.train()\n        train_loss = 0.0\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n        for images, meta, targets in pbar:\n            images = images.cuda(non_blocking=True)\n            meta = meta.cuda(non_blocking=True)\n            targets = targets.cuda(non_blocking=True)\n            \n            optimizer.zero_grad()\n            with autocast(device_type='cuda'):\n                outputs = model(images, meta)\n                loss = criterion(outputs, targets)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            \n            train_loss += loss.item()\n            pbar.set_postfix(loss=loss.item())\n        \n        # Validation loop\n        model.eval()\n        val_loss = 0.0\n        preds, truths = [], []\n        with torch.no_grad():\n            for images, meta, targets in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n                images = images.cuda(non_blocking=True)\n                meta = meta.cuda(non_blocking=True)\n                targets = targets.cuda(non_blocking=True)\n                \n                with autocast(device_type='cuda'):\n                    outputs = model(images, meta)\n                    loss = criterion(outputs, targets)\n                \n                val_loss += loss.item()\n                preds.append(outputs.cpu().numpy())\n                truths.append(targets.cpu().numpy())\n        \n        # Metrics calculation\n        train_loss /= len(train_loader)\n        val_loss /= len(val_loader)\n        preds = np.concatenate(preds)\n        truths = np.concatenate(truths)\n        mae = mean_absolute_error(truths, preds)\n        \n        print(f\"Epoch {epoch+1}/{epochs}\")\n        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val MAE: {mae:.4f}\")\n        \n        # Model checkpointing based on MAE\n        if mae < best_mae:\n            best_mae = mae\n            torch.save(model.state_dict(), f\"best_model_fold{fold}.pth\")\n        \n        scheduler.step()\n    \n    return best_mae\n\n# Inference with TTA\ndef predict(test_df, model_paths, batch_size=32):\n    test_df[\"path\"] = \"/kaggle/input/lacuna-solar-survey-challenge/images/\" + test_df[\"ID\"] + \".jpg\"\n    test_ds = SolarPanelDataset(test_df, transform=test_transform, to_train=False)\n    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n    \n    predictions = np.zeros((len(test_df), 2))\n    for path in model_paths:\n        model = EfficientNetV2Meta().cuda()\n        model.load_state_dict(torch.load(path, weights_only=True))  # Safer loading\n        model.eval()\n        \n        tta_preds = []\n        with torch.no_grad():\n            for images, meta in tqdm(test_loader, desc=\"Inference\"):\n                images = images.cuda()\n                meta = meta.cuda()\n                with autocast(device_type='cuda'):\n                    outputs = model(images, meta)\n                tta_preds.append(outputs.cpu().numpy())\n        \n        predictions += np.concatenate(tta_preds)\n    \n    return predictions / len(model_paths)\n\n# Main Execution\nif __name__ == \"__main__\":\n    # Train multiple folds\n    folds = 3\n    model_paths = []\n    for fold in range(folds):\n        print(f\"Training fold {fold+1}/{folds}\")\n        best_mae = train(fold=fold, epochs=25, batch_size=32)\n        model_paths.append(f\"best_model_fold{fold}.pth\")\n    \n    # Prepare submission\n    test_df = pd.read_csv(\"/kaggle/input/lacuna-solar-survey-challenge/Test.csv\")\n    predictions = predict(test_df, model_paths, batch_size=64)\n    \n    # Create submissions\n    submission = pd.DataFrame({\n        \"ID\": np.repeat(test_df[\"ID\"].values, 2),\n        \"Target\": predictions.flatten()\n    })\n    submission[\"ID\"] += np.where(\n        submission.groupby(\"ID\").cumcount() == 0,\n        \"_boil\",\n        \"_pan\"\n    )\n    submission.to_csv(\"submission_original.csv\", index=False)\n    \n    int_submission = submission.copy()\n    int_submission[\"Target\"] = np.round(int_submission[\"Target\"]).astype(int)\n    int_submission.to_csv(\"submission_integer.csv\", index=False)\n    \n    print(\"Submissions saved with shapes:\", submission.shape, int_submission.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T09:05:41.889169Z","iopub.execute_input":"2025-03-18T09:05:41.889542Z","iopub.status.idle":"2025-03-18T10:47:48.756949Z","shell.execute_reply.started":"2025-03-18T09:05:41.889515Z","shell.execute_reply":"2025-03-18T10:47:48.755745Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SolarPanelDataset(Dataset):\n    def __init__(self, dataframe, transform=None, to_train=True):\n        self.dataframe = dataframe\n        self.transform = transform\n        self.to_train = to_train\n        self.placement_map = {\"roof\": 0, \"openspace\": 1, \"r_openspace\": 2, \"S-unknown\": 3}\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        image = cv2.imread(row[\"path\"])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Correct color conversion\n\n        # Improved metadata encoding\n        metadata = torch.zeros(5)\n        metadata[0] = 1.0 if row[\"img_origin\"] == \"D\" else 0.0\n        placement = self.placement_map.get(row[\"placement\"], 3)\n        metadata[1 + placement] = 1.0  # One-hot encoding\n\n        if self.transform:\n            image = self.transform(image=image)['image']\n\n        if self.to_train:\n            target = torch.tensor([row[\"boil_nbr\"], row[\"pan_nbr\"]], dtype=torch.float32)\n            return image, metadata, target\n        return image, metadata\n\n\n# Advanced Augmentation\ntrain_transform = A.Compose([\n    A.RandomResizedCrop(512, 512, scale=(0.7, 1.0)),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n    A.CLAHE(clip_limit=4.0, p=0.5),\n    A.HueSaturationValue(p=0.3),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\ntrain_df = pd.read_csv(\"/kaggle/input/lacuna-solar-survey-challenge/Train.csv\")\ntrain_df = train_df.groupby(\"ID\").agg({\n\"boil_nbr\": \"sum\",\n\"pan_nbr\": \"sum\",\n\"img_origin\": \"first\",\n\"placement\": \"first\"\n}).reset_index()\ntrain_df[\"path\"] = \"/kaggle/input/lacuna-solar-survey-challenge/images/\" + train_df[\"ID\"] + \".jpg\"\n\n\n\ntrain_ds = SolarPanelDataset(train_df, transform=train_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:50:07.263921Z","iopub.execute_input":"2025-03-19T06:50:07.264274Z","iopub.status.idle":"2025-03-19T06:50:07.301368Z","shell.execute_reply.started":"2025-03-19T06:50:07.264250Z","shell.execute_reply":"2025-03-19T06:50:07.300475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:50:07.302831Z","iopub.execute_input":"2025-03-19T06:50:07.303247Z","iopub.status.idle":"2025-03-19T06:50:07.314484Z","shell.execute_reply.started":"2025-03-19T06:50:07.303212Z","shell.execute_reply":"2025-03-19T06:50:07.313650Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:47:26.973333Z","iopub.execute_input":"2025-03-19T06:47:26.973675Z","iopub.status.idle":"2025-03-19T06:47:26.979104Z","shell.execute_reply.started":"2025-03-19T06:47:26.973649Z","shell.execute_reply":"2025-03-19T06:47:26.978260Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image, metadata, target = train_ds[1000]\nprint(\"Image shape:\", image.shape)\nprint(\"Metadata:\", metadata)\nprint(\"Target:\", target)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:47:45.329155Z","iopub.execute_input":"2025-03-19T06:47:45.329478Z","iopub.status.idle":"2025-03-19T06:47:45.532016Z","shell.execute_reply.started":"2025-03-19T06:47:45.329454Z","shell.execute_reply":"2025-03-19T06:47:45.531012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=42)\nsplits = list(kf.split(train_df))\ntrain_idx, val_idx = splits[fold]\n\ntrain_ds = SolarPanelDataset(train_df.iloc[train_idx], transform=train_transform)\nval_ds = SolarPanelDataset(train_df.iloc[val_idx], transform=test_transform)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:53:32.279581Z","iopub.execute_input":"2025-03-19T06:53:32.279974Z","iopub.status.idle":"2025-03-19T06:53:32.288983Z","shell.execute_reply.started":"2025-03-19T06:53:32.279944Z","shell.execute_reply":"2025-03-19T06:53:32.287839Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.iloc[train_idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:55:59.212614Z","iopub.execute_input":"2025-03-19T06:55:59.212971Z","iopub.status.idle":"2025-03-19T06:55:59.226368Z","shell.execute_reply.started":"2025-03-19T06:55:59.212940Z","shell.execute_reply":"2025-03-19T06:55:59.225263Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(splits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T07:03:26.878692Z","iopub.execute_input":"2025-03-19T07:03:26.879070Z","iopub.status.idle":"2025-03-19T07:03:26.886029Z","shell.execute_reply.started":"2025-03-19T07:03:26.879043Z","shell.execute_reply":"2025-03-19T07:03:26.884332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:55:49.579203Z","iopub.execute_input":"2025-03-19T06:55:49.579577Z","iopub.status.idle":"2025-03-19T06:55:49.584735Z","shell.execute_reply.started":"2025-03-19T06:55:49.579515Z","shell.execute_reply":"2025-03-19T06:55:49.583816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:55:38.229922Z","iopub.execute_input":"2025-03-19T06:55:38.230284Z","iopub.status.idle":"2025-03-19T06:55:38.236083Z","shell.execute_reply.started":"2025-03-19T06:55:38.230255Z","shell.execute_reply":"2025-03-19T06:55:38.235164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(splits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:54:04.399509Z","iopub.execute_input":"2025-03-19T06:54:04.399908Z","iopub.status.idle":"2025-03-19T06:54:04.405623Z","shell.execute_reply.started":"2025-03-19T06:54:04.399878Z","shell.execute_reply":"2025-03-19T06:54:04.404327Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(splits[1][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:55:08.693516Z","iopub.execute_input":"2025-03-19T06:55:08.693908Z","iopub.status.idle":"2025-03-19T06:55:08.699240Z","shell.execute_reply.started":"2025-03-19T06:55:08.693878Z","shell.execute_reply":"2025-03-19T06:55:08.698375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(splits[1][1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:55:12.098521Z","iopub.execute_input":"2025-03-19T06:55:12.098928Z","iopub.status.idle":"2025-03-19T06:55:12.104486Z","shell.execute_reply.started":"2025-03-19T06:55:12.098862Z","shell.execute_reply":"2025-03-19T06:55:12.103624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(splits[0][1])/(len(splits[0][1]) + len(splits[0][0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T06:55:20.994678Z","iopub.execute_input":"2025-03-19T06:55:20.995012Z","iopub.status.idle":"2025-03-19T06:55:21.001996Z","shell.execute_reply.started":"2025-03-19T06:55:20.994985Z","shell.execute_reply":"2025-03-19T06:55:21.000930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}